{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c4b3b1",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "<h1>Final Assessment - Advanced Natural Language Processing</h1>\n",
    "\n",
    "<i>\n",
    "\n",
    "Course: 22DM015 Advanced Methods in Natural Language Processing <br>\n",
    "\n",
    "Author(s): Ferran Boada Bergadà, Julián Romero, Lucia Sauer, Moritz Peist<br>\n",
    "\n",
    "Programme: DSDM\n",
    "\n",
    "<hr>\n",
    "\n",
    "....\n",
    "\n",
    "</i>\n",
    "\n",
    "</center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155a530",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40288318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ea1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "DATA_PATH = \"../data/\"\n",
    "SPLITS = {\n",
    "    \"train\": \"patent/train-00000-of-00001.parquet\",\n",
    "    \"validation\": \"patent/validation-00000-of-00001.parquet\",\n",
    "    \"test\": \"patent/test-00000-of-00001.parquet\",\n",
    "}\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "LABELS = {\n",
    "    0: \"Human Necessities\",\n",
    "    1: \"Performing Operations; Transporting\",\n",
    "    2: \"Chemistry; Metallurgy\",\n",
    "    3: \"Textiles; Paper\",\n",
    "    4: \"Fixed Constructions\",\n",
    "    5: \"Mechanical Engineering; Lighting; Heating; Weapons; Blasting\",\n",
    "    6: \"Physics\",\n",
    "    7: \"Electricity\",\n",
    "    8: \"General tagging of new or cross-sectional technology\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7f60d",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df04b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and persistence\n",
    "\n",
    "\n",
    "def load_split(\n",
    "    split_name, split_path, data_path=\"../data\", dataset=\"ccdv/patent-classification\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a specific split of the dataset, checking for local cache first.\n",
    "    If the split is not cached locally, it will be downloaded and saved.\n",
    "    Args:\n",
    "        split_name (str): Name of the split (e.g., 'train', 'validation', 'test').\n",
    "        split_path (str): Path to the split file in the dataset.\n",
    "        data_path (str): Local path where the dataset is cached.\n",
    "        dataset (str): Name of the dataset on Hugging Face Hub.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the split data.\n",
    "    \"\"\"\n",
    "    local_path = os.path.join(data_path, split_path)\n",
    "    if os.path.exists(local_path):\n",
    "        return pd.read_parquet(local_path)\n",
    "\n",
    "    # Download and cache\n",
    "    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "    df = pd.read_parquet(f\"hf://datasets/{dataset}/{split_path}\")\n",
    "    df.to_parquet(local_path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05569bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_split(\"train\", SPLITS[\"train\"])\n",
    "df_validation = load_split(\"validation\", SPLITS[\"validation\"])\n",
    "df_test = load_split(\"test\", SPLITS[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84237d",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760fc1a",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c6d25",
   "metadata": {},
   "source": [
    "Here we load a BERT model trained by Google on patents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5eb6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Loading a bert model directly\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"anferico/bert-for-patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39692d",
   "metadata": {},
   "source": [
    "### a. BERT Model with Limited Data (0.5 points): \n",
    "Train a BERT-based model using only 32 labeled examples and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472841ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 32 subsample of the training set, ensuring stratification\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=32, random_state=RANDOM_SEED)\n",
    "train_idx, _ = next(sss.split(df_train, df_train[\"label\"]))\n",
    "df_train32 = df_train.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63db7b7",
   "metadata": {},
   "source": [
    "#### a.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6dac644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for the patent BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"anferico/bert-for-patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff0c9c",
   "metadata": {},
   "source": [
    "#### a.2 Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412c180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens:\n",
      "[CLS]: [CLS] (ID: 2)\n",
      "[SEP]: [SEP] (ID: 3)\n",
      "[PAD]: [PAD] (ID: 0)\n",
      "[UNK]: [UNK] (ID: 1)\n"
     ]
    }
   ],
   "source": [
    "# The tokenizer already has the special tokens configured\n",
    "print(\"Special tokens:\")\n",
    "print(f\"[CLS]: {tokenizer.cls_token} (ID: {tokenizer.cls_token_id})\")\n",
    "print(f\"[SEP]: {tokenizer.sep_token} (ID: {tokenizer.sep_token_id})\")\n",
    "print(f\"[PAD]: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"[UNK]: {tokenizer.unk_token} (ID: {tokenizer.unk_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b5ac0",
   "metadata": {},
   "source": [
    "#### a.3 Tokens to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14e2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the text data\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Tokenize the 32 training examples\n",
    "train_encodings = tokenizer(\n",
    "    df_train32[\"text\"].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514e9b0",
   "metadata": {},
   "source": [
    "#### a.4 Padding and Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab58b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset class\n",
    "class PatentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for key, val in self.encodings.items():\n",
    "            if torch.is_tensor(val[idx]):\n",
    "                item[key] = val[idx].detach().clone()\n",
    "            else:\n",
    "                item[key] = torch.tensor(val[idx])\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = PatentDataset(train_encodings, df_train32[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d20b1",
   "metadata": {},
   "source": [
    "#### a.5 Model Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"anferico/bert-for-patents\",\n",
    "    num_labels=len(LABELS.items()),  # 9 patent classes\n",
    ")\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_32_samples\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    eval_strategy=\"no\",  # No validation set for this small training\n",
    "    seed=RANDOM_SEED,\n",
    "    report_to=[],  # Disable all logging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05973316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT model with 32 labeled examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmpei\\OneDrive\\Uni\\BSE\\Trimester 3\\ANLP\\anlp_final_project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\mmpei\\AppData\\Local\\Temp\\ipykernel_28408\\1803203683.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 10:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.091800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=2.0821491877237954, metrics={'train_runtime': 723.0173, 'train_samples_per_second': 0.133, 'train_steps_per_second': 0.017, 'total_flos': 89467526873088.0, 'train_loss': 2.0821491877237954, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training BERT model with 32 labeled examples...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b760e",
   "metadata": {},
   "source": [
    "#### a.6 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare validation data for evaluation\n",
    "val_encodings = tokenizer(\n",
    "    df_validation[\"text\"].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "val_dataset = PatentDataset(val_encodings, df_validation[\"label\"].tolist())\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "eval_results = trainer.evaluate(val_dataset)\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c22a85",
   "metadata": {},
   "source": [
    "#### a.7 Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6856c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for analysis\n",
    "predictions = trainer.predict(val_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = df_validation[\"label\"].tolist()\n",
    "\n",
    "# Calculate per-class metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=list(LABELS.values())))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d277de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline comparison (random classifier)\n",
    "n_classes = len(LABELS)\n",
    "random_accuracy = 1.0 / n_classes\n",
    "print(f\"\\nRandom Baseline Accuracy: {random_accuracy:.4f}\")\n",
    "print(f\"Model Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Improvement over random: {eval_results['eval_accuracy'] - random_accuracy:.4f}\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\n=== BERT Model with 32 Labeled Examples - Performance Summary ===\")\n",
    "print(f\"Training samples: 32\")\n",
    "print(f\"Validation accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation F1-score: {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"Validation precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Validation recall: {eval_results['eval_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf6aa54",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b72de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline results for later comparison\n",
    "baseline_results = {\n",
    "    \"accuracy\": eval_results[\"eval_accuracy\"],\n",
    "    \"f1\": eval_results[\"eval_f1\"],\n",
    "    \"precision\": eval_results[\"eval_precision\"],\n",
    "    \"recall\": eval_results[\"eval_recall\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b33b7d",
   "metadata": {},
   "source": [
    "### b. Dataset Augmentation (1 point): \n",
    "Experiment with an automated technique to increase your dataset size without using LLMs (chatGPT / Mistral / Gemini / etc...). Evaluate the impact on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad8714",
   "metadata": {},
   "source": [
    "### b.1 Back-Translation Setup with MarianMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83acc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MarianMT models for back-translation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d5c552dc184c5db810412f44106927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmpei\\miniforge3\\envs\\anlp\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mmpei\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-es. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ca49c5217547bfa6cc4c10cc971fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89d39277cab4b7ea1ffa087c3de2163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fe2ff82afc4bb2b822ab557412a558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75fe58dbd1d4ffb978597f67fce5fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmpei\\miniforge3\\envs\\anlp\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ccb2b0a19e49bf95f5d21f4245267a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638fe56d93424563a02b95423816cdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878d1241f01c4b35b99ea416f912e922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmpei\\miniforge3\\envs\\anlp\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mmpei\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-es-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484232edc3084105bd824c8c80f47006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e4bf857fb34d029afc7031895e7056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938ca8c5c09a467e9b19ca227a81e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcbc816efc44aebbb635125be521ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ce6079996d4faa8a7586a55fd113db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dcbe8ee5ea41b38736927d29b574c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc9210bea864c97a172ea50ee6d13b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianMT models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecadb6614b8408888f66e0b99e2125d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load MarianMT models for back-translation (English <-> Spanish)\n",
    "print(\"Loading MarianMT models for back-translation...\")\n",
    "\n",
    "# English to Spanish model\n",
    "en_es_model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "en_es_tokenizer = MarianTokenizer.from_pretrained(en_es_model_name)\n",
    "en_es_model = MarianMTModel.from_pretrained(en_es_model_name)\n",
    "\n",
    "# Spanish to English model\n",
    "es_en_model_name = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "es_en_tokenizer = MarianTokenizer.from_pretrained(es_en_model_name)\n",
    "es_en_model = MarianMTModel.from_pretrained(es_en_model_name)\n",
    "\n",
    "print(\"MarianMT models loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8eed7",
   "metadata": {},
   "source": [
    "### b.2 Back-Translation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b6c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_spanish(texts, batch_size=8):\n",
    "    \"\"\"Translate English texts to Spanish\"\"\"\n",
    "    translated_texts = []\n",
    "\n",
    "    # Calculate total number of batches for progress bar\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, len(texts), batch_size),\n",
    "        desc=\"Translating EN→ES\",\n",
    "        total=total_batches,\n",
    "        unit=\"batch\",\n",
    "    ):\n",
    "        batch = texts[i : i + batch_size]\n",
    "\n",
    "        # Tokenize and translate\n",
    "        inputs = en_es_tokenizer(\n",
    "            batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        )\n",
    "        translated = en_es_model.generate(\n",
    "            **inputs, max_length=512, num_beams=4, early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode translations\n",
    "        batch_translations = en_es_tokenizer.batch_decode(\n",
    "            translated, skip_special_tokens=True\n",
    "        )\n",
    "        translated_texts.extend(batch_translations)\n",
    "\n",
    "    return translated_texts\n",
    "\n",
    "\n",
    "def translate_to_english(texts, batch_size=8):\n",
    "    \"\"\"Translate Spanish texts back to English\"\"\"\n",
    "    translated_texts = []\n",
    "\n",
    "    # Calculate total number of batches for progress bar\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, len(texts), batch_size),\n",
    "        desc=\"Translating ES→EN\",\n",
    "        total=total_batches,\n",
    "        unit=\"batch\",\n",
    "    ):\n",
    "        batch = texts[i : i + batch_size]\n",
    "\n",
    "        # Tokenize and translate\n",
    "        inputs = es_en_tokenizer(\n",
    "            batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        )\n",
    "        translated = es_en_model.generate(\n",
    "            **inputs, max_length=512, num_beams=4, early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode translations\n",
    "        batch_translations = es_en_tokenizer.batch_decode(\n",
    "            translated, skip_special_tokens=True\n",
    "        )\n",
    "        translated_texts.extend(batch_translations)\n",
    "\n",
    "    return translated_texts\n",
    "\n",
    "\n",
    "def back_translate(texts, target_lang=\"es\"):\n",
    "    \"\"\"Perform back-translation: en -> target_lang -> en\"\"\"\n",
    "    print(f\"Starting back-translation for {len(texts)} texts...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Step 1: Translate to target language\n",
    "    if target_lang == \"es\":\n",
    "        intermediate = translate_to_spanish(texts)\n",
    "        # Step 2: Translate back to English\n",
    "        back_translated = translate_to_english(intermediate)\n",
    "    else:\n",
    "        raise ValueError(f\"Language {target_lang} not supported. Use 'es' for Spanish.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Back-translation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return back_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8744c",
   "metadata": {},
   "source": [
    "### b.3 Generate Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caac1dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 32\n",
      "\n",
      "Generating augmented data through back-translation...\n",
      "Starting back-translation for 32 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7c38af09f844ca865fdce7ee9ee7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating EN→ES:   0%|          | 0/4 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e085488cd749959091c1f56f325057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating ES→EN:   0%|          | 0/4 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back-translation completed in 809.68 seconds\n",
      "\n",
      "=== Back-Translation Examples ===\n",
      "\n",
      "Example 1:\n",
      "Original:  reference will now be made in detail to the present preferred embodiments of the invention , examples of which are illustrated in the accompanying drawings . wherever possible , the same reference num...\n",
      "Augmented: the reference shall now be made in detail to the current preferred incarnations of the invention , examples of which are illustrated in the attached drawings . Wherever possible , the same reference n...\n",
      "\n",
      "Example 2:\n",
      "Original:  all terms as used herein in this specification , unless otherwise stated , shall be understood in their ordinary meaning as known in the art . other more specific definitions are as follows : the term...\n",
      "Augmented: all the terms used in this specification , unless otherwise stated , shall be understood in their ordinary sense as being known in art . Other more specific definitions are the following : the term “ ...\n",
      "\n",
      "Example 3:\n",
      "Original:  in the following , a targets throwing device used in shooting sports such as clay pigeon shooting and thus frequently using clay targets will be described . it should be noted here that the present in...\n",
      "Augmented: In the next pin , a target launch device used in shooting sports such as shooting with clay pigeon and therefore frequently using clay targets . It should be noted here that the present invention is n...\n",
      "\n",
      "Valid augmented samples: 32 out of 32\n",
      "Total training samples after augmentation: 64\n",
      "Data expansion factor: 2.00x\n"
     ]
    }
   ],
   "source": [
    "# Extract original texts and labels from 32-sample training set\n",
    "original_texts = df_train32[\"text\"].tolist()\n",
    "original_labels = df_train32[\"label\"].tolist()\n",
    "\n",
    "print(f\"Original training set size: {len(original_texts)}\")\n",
    "\n",
    "# Perform back-translation to create augmented samples\n",
    "print(\"\\nGenerating augmented data through back-translation...\")\n",
    "augmented_texts = back_translate(original_texts, target_lang=\"es\")\n",
    "\n",
    "# Quality check: show examples of original vs augmented texts\n",
    "print(\"\\n=== Back-Translation Examples ===\")\n",
    "for i in range(min(3, len(original_texts))):\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(f\"Original:  {original_texts[i][:200]}...\")\n",
    "    print(f\"Augmented: {augmented_texts[i][:200]}...\")\n",
    "\n",
    "# Filter augmented texts (remove identical ones)\n",
    "filtered_augmented = []\n",
    "filtered_labels = []\n",
    "\n",
    "for orig, aug, label in zip(original_texts, augmented_texts, original_labels):\n",
    "    # Only keep augmented text if it's different from original\n",
    "    if orig.strip().lower() != aug.strip().lower():\n",
    "        filtered_augmented.append(aug)\n",
    "        filtered_labels.append(label)\n",
    "\n",
    "print(\n",
    "    f\"\\nValid augmented samples: {len(filtered_augmented)} out of {len(augmented_texts)}\"\n",
    ")\n",
    "\n",
    "# Combine original and augmented data\n",
    "combined_texts = original_texts + filtered_augmented\n",
    "combined_labels = original_labels + filtered_labels\n",
    "\n",
    "print(f\"Total training samples after augmentation: {len(combined_texts)}\")\n",
    "print(f\"Data expansion factor: {len(combined_texts) / len(original_texts):.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ae964",
   "metadata": {},
   "source": [
    "### b.4 Train Model on Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare augmented dataset for training\n",
    "augmented_encodings = tokenizer(\n",
    "    combined_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "augmented_train_dataset = PatentDataset(augmented_encodings, combined_labels)\n",
    "\n",
    "# Setup training for augmented model\n",
    "augmented_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"anferico/bert-for-patents\", num_labels=9\n",
    ")\n",
    "\n",
    "augmented_training_args = TrainingArguments(\n",
    "    output_dir=\"./results_augmented\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=20,  # Slightly more warmup for larger dataset\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_augmented\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    eval_strategy=\"no\",\n",
    "    seed=RANDOM_SEED,\n",
    "    report_to=[],  # Disable all logging, e.g. wandb\n",
    ")\n",
    "\n",
    "# Train augmented model\n",
    "augmented_trainer = Trainer(\n",
    "    model=augmented_model,\n",
    "    args=augmented_training_args,\n",
    "    train_dataset=augmented_train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Training BERT model with back-translation augmented data...\")\n",
    "augmented_trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe735f5",
   "metadata": {},
   "source": [
    "### b.5 Evaluate Augmented Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate augmented model on validation set\n",
    "print(\"Evaluating augmented model on validation set...\")\n",
    "augmented_eval_results = augmented_trainer.evaluate(val_dataset)\n",
    "\n",
    "print(\"\\nAugmented Model Validation Results:\")\n",
    "for key, value in augmented_eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbe122",
   "metadata": {},
   "source": [
    "### b.6 Compare Results: Baseline vs Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET AUGMENTATION IMPACT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 TRAINING DATA COMPARISON:\")\n",
    "print(\"  Baseline (32 samples):     32 samples\")\n",
    "print(f\"  Augmented dataset:         {len(combined_texts)} samples\")\n",
    "print(f\"  Expansion factor:          {len(combined_texts) / 32:.2f}x\")\n",
    "\n",
    "print(\"\\n📈 PERFORMANCE COMPARISON:\")\n",
    "metrics = [\"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "for metric in metrics:\n",
    "    baseline_val = baseline_results[metric]\n",
    "    augmented_val = augmented_eval_results[f\"eval_{metric}\"]\n",
    "    improvement = augmented_val - baseline_val\n",
    "    improvement_pct = (improvement / baseline_val) * 100\n",
    "\n",
    "    print(f\"  {metric.upper()}:\")\n",
    "    print(f\"    Baseline:     {baseline_val:.4f}\")\n",
    "    print(f\"    Augmented:    {augmented_val:.4f}\")\n",
    "    print(f\"    Improvement:  {improvement:+.4f} ({improvement_pct:+.1f}%)\")\n",
    "    print()\n",
    "\n",
    "# Statistical significance test (simple)\n",
    "accuracy_improvement = (\n",
    "    augmented_eval_results[\"eval_accuracy\"] - baseline_results[\"accuracy\"]\n",
    ")\n",
    "print(\"🎯 KEY FINDINGS:\")\n",
    "print(f\"  • Accuracy improvement: {accuracy_improvement:+.4f}\")\n",
    "if accuracy_improvement > 0.01:  # 1% threshold\n",
    "    print(\"  • Result: SIGNIFICANT improvement with back-translation\")\n",
    "elif accuracy_improvement > 0:\n",
    "    print(\"  • Result: MARGINAL improvement with back-translation\")\n",
    "else:\n",
    "    print(\"  • Result: NO improvement with back-translation\")\n",
    "\n",
    "print(\"\\n✅ AUGMENTATION TECHNIQUE ASSESSMENT:\")\n",
    "print(\"  • Back-translation with MarianMT (en→es→en)\")\n",
    "print(f\"  • Generated {len(filtered_augmented)} valid augmented samples\")\n",
    "print(\n",
    "    f\"  • Quality: {len(filtered_augmented) / len(original_texts) * 100:.1f}% of attempts were unique\"\n",
    ")\n",
    "print(f\"  • Impact: {accuracy_improvement:+.4f} accuracy change\")\n",
    "\n",
    "# Detailed analysis per class\n",
    "augmented_predictions = augmented_trainer.predict(val_dataset)\n",
    "augmented_pred_labels = np.argmax(augmented_predictions.predictions, axis=1)\n",
    "\n",
    "print(\"\\n📋 DETAILED CLASSIFICATION REPORT (Augmented Model):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        true_labels, augmented_pred_labels, target_names=list(LABELS.values())\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb2bcc",
   "metadata": {},
   "source": [
    "### c. Zero-Shot Learning with LLM (0.5 points):\n",
    "Apply a LLM (chatGPT/Claude/Mistral/Gemini/...) in a zero-shot learning setup. Document the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9aebb",
   "metadata": {},
   "source": [
    "### d. Data Generation with LLM (1 point):\n",
    "Use a LLM (chatGPT/Claude/Mistral/Gemini/...) to generate new, labeled dataset points. Train your BERT model with it + the 32 labels. Analyze how this impacts model metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a56e7",
   "metadata": {},
   "source": [
    "### e. Optimal Technique Application (0.5 points):\n",
    " Based on the previous experiments, apply the most effective technique(s) to further improve your model's performance. Comment your results and propose improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a3639",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0ea81",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
